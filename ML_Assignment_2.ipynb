{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Assignment 2 â€“ Bike Sharing Classification\n",
        "\n",
        "This notebook implements **6 classification models** on the Bike Sharing dataset:\n",
        "1. Logistic Regression  \n",
        "2. Decision Tree Classifier  \n",
        "3. K-Nearest Neighbor Classifier  \n",
        "4. Naive Bayes Classifier (Gaussian)  \n",
        "5. Random Forest (Ensemble)  \n",
        "6. XGBoost (Ensemble)  \n",
        "\n",
        "**Evaluation metrics:** Accuracy, AUC, Precision, Recall, F1 Score, MCC  \n",
        "**Data:** `bike_train.csv` (training), `bike_test.csv` (test)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
        "    matthews_corrcoef, confusion_matrix, classification_report\n",
        ")\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "MODEL_DIR = 'model'\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and explore data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df = pd.read_csv('bike_train.csv')\n",
        "test_df = pd.read_csv('bike_test.csv')\n",
        "print('Train shape:', train_df.shape)\n",
        "print('Test shape:', test_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "Target `count` is continuous; we bin it into 4 classes for multi-class classification.  \n",
        "We use at least 12 features: season, holiday, workingday, weather, temp, atemp, humidity, windspeed + year, month, day, hour from datetime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def preprocess_train(df):\n",
        "    df = df.copy()\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "    df['year'] = df['datetime'].dt.year\n",
        "    df['month'] = df['datetime'].dt.month\n",
        "    df['day'] = df['datetime'].dt.day\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    # Drop datetime and leaky columns (casual + registered = count)\n",
        "    df = df.drop(columns=['datetime', 'casual', 'registered'])\n",
        "    # Bin count into 4 classes (quartile-based)\n",
        "    df['count_class'] = pd.qcut(df['count'], q=4, labels=[0, 1, 2, 3], duplicates='drop')\n",
        "    df = df.drop(columns=['count'])\n",
        "    return df\n",
        "\n",
        "def preprocess_test(df):\n",
        "    df = df.copy()\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "    df['year'] = df['datetime'].dt.year\n",
        "    df['month'] = df['datetime'].dt.month\n",
        "    df['day'] = df['datetime'].dt.day\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    df = df.drop(columns=['datetime'])\n",
        "    return df\n",
        "\n",
        "train_processed = preprocess_train(train_df)\n",
        "train_processed.dropna(inplace=True)\n",
        "feature_cols = [c for c in train_processed.columns if c != 'count_class']\n",
        "print('Feature columns (count = {}):'.format(len(feature_cols)), feature_cols)\n",
        "print('Class distribution:')\n",
        "print(train_processed['count_class'].value_counts().sort_index())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = train_processed[feature_cols]\n",
        "y = train_processed['count_class'].astype(int)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "joblib.dump(scaler, os.path.join(MODEL_DIR, 'scaler.joblib'))\n",
        "joblib.dump(feature_cols, os.path.join(MODEL_DIR, 'feature_cols.joblib'))\n",
        "print('Train size:', X_train.shape[0], '| Validation size:', X_val.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation helper and model training\n",
        "\n",
        "Train all 6 models and compute Accuracy, AUC, Precision, Recall, F1, MCC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_model(y_true, y_pred, y_proba=None, name='Model'):\n",
        "    n_classes = len(np.unique(y_true))\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    if y_proba is not None and n_classes == 2:\n",
        "        auc = roc_auc_score(y_true, y_proba[:, 1])\n",
        "    elif y_proba is not None and n_classes > 2:\n",
        "        auc = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
        "    else:\n",
        "        auc = 0.0\n",
        "    return {\n",
        "        'Accuracy': acc, 'AUC': auc, 'Precision': precision,\n",
        "        'Recall': recall, 'F1': f1, 'MCC': mcc\n",
        "    }\n",
        "\n",
        "results = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1. Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_val_scaled)\n",
        "y_proba_lr = lr.predict_proba(X_val_scaled)\n",
        "res_lr = evaluate_model(y_val, y_pred_lr, y_proba_lr, 'Logistic Regression')\n",
        "results.append(('Logistic Regression', res_lr))\n",
        "joblib.dump(lr, os.path.join(MODEL_DIR, 'logistic_regression.joblib'))\n",
        "print('Logistic Regression:', res_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2. Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "dt.fit(X_train, y_train)  # Tree often works without scaling\n",
        "y_pred_dt = dt.predict(X_val)\n",
        "y_proba_dt = dt.predict_proba(X_val)\n",
        "res_dt = evaluate_model(y_val, y_pred_dt, y_proba_dt, 'Decision Tree')\n",
        "results.append(('Decision Tree', res_dt))\n",
        "joblib.dump(dt, os.path.join(MODEL_DIR, 'decision_tree.joblib'))\n",
        "print('Decision Tree:', res_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3. K-Nearest Neighbor\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = knn.predict(X_val_scaled)\n",
        "y_proba_knn = knn.predict_proba(X_val_scaled)\n",
        "res_knn = evaluate_model(y_val, y_pred_knn, y_proba_knn, 'kNN')\n",
        "results.append(('kNN', res_knn))\n",
        "joblib.dump(knn, os.path.join(MODEL_DIR, 'knn.joblib'))\n",
        "print('kNN:', res_knn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 4. Naive Bayes (Gaussian)\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_scaled, y_train)\n",
        "y_pred_nb = nb.predict(X_val_scaled)\n",
        "y_proba_nb = nb.predict_proba(X_val_scaled)\n",
        "res_nb = evaluate_model(y_val, y_pred_nb, y_proba_nb, 'Naive Bayes')\n",
        "results.append(('Naive Bayes', res_nb))\n",
        "joblib.dump(nb, os.path.join(MODEL_DIR, 'naive_bayes.joblib'))\n",
        "print('Naive Bayes:', res_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5. Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
        "rf.fit(X_train, y_train)  # RF typically no scaling\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "y_proba_rf = rf.predict_proba(X_val)\n",
        "res_rf = evaluate_model(y_val, y_pred_rf, y_proba_rf, 'Random Forest')\n",
        "results.append(('Random Forest (Ensemble)', res_rf))\n",
        "joblib.dump(rf, os.path.join(MODEL_DIR, 'random_forest.joblib'))\n",
        "print('Random Forest:', res_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 6. XGBoost\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train, y_train)  # XGBoost typically no scaling\n",
        "y_pred_xgb = xgb_model.predict(X_val)\n",
        "y_proba_xgb = xgb_model.predict_proba(X_val)\n",
        "res_xgb = evaluate_model(y_val, y_pred_xgb, y_proba_xgb, 'XGBoost')\n",
        "results.append(('XGBoost (Ensemble)', res_xgb))\n",
        "joblib.dump(xgb_model, os.path.join(MODEL_DIR, 'xgboost.joblib'))\n",
        "print('XGBoost:', res_xgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comparison table (all metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "comparison = pd.DataFrame(\n",
        "    [dict(name=name, **r) for name, r in results]\n",
        ").set_index('name')\n",
        "comparison.round(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Confusion matrices and classification reports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions = {\n",
        "    'Logistic Regression': y_pred_lr,\n",
        "    'Decision Tree': y_pred_dt,\n",
        "    'kNN': y_pred_knn,\n",
        "    'Naive Bayes': y_pred_nb,\n",
        "    'Random Forest': y_pred_rf,\n",
        "    'XGBoost': y_pred_xgb\n",
        "}\n",
        "for name, y_pred in predictions.items():\n",
        "    print('---', name, '---')\n",
        "    print(confusion_matrix(y_val, y_pred))\n",
        "    print(classification_report(y_val, y_pred, zero_division=0))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Predict on test set and save (optional)\n",
        "\n",
        "Preprocess test data and generate predictions using the saved scaler and one model (e.g. Random Forest uses raw features). For Streamlit we load from `model/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save validation metrics and confusion matrices for Streamlit app (no need to ship train CSV)\n",
        "name_to_pred = {\n",
        "    'Logistic Regression': y_pred_lr,\n",
        "    'Decision Tree': y_pred_dt,\n",
        "    'kNN': y_pred_knn,\n",
        "    'Naive Bayes': y_pred_nb,\n",
        "    'Random Forest (Ensemble)': y_pred_rf,\n",
        "    'XGBoost (Ensemble)': y_pred_xgb,\n",
        "}\n",
        "name_to_proba = {\n",
        "    'Logistic Regression': y_proba_lr,\n",
        "    'Decision Tree': y_proba_dt,\n",
        "    'kNN': y_proba_knn,\n",
        "    'Naive Bayes': y_proba_nb,\n",
        "    'Random Forest (Ensemble)': y_proba_rf,\n",
        "    'XGBoost (Ensemble)': y_proba_xgb,\n",
        "}\n",
        "val_results = {}\n",
        "for name, y_pred in name_to_pred.items():\n",
        "    y_proba = name_to_proba[name]\n",
        "    val_results[name] = {\n",
        "        'metrics': evaluate_model(y_val, y_pred, y_proba, name),\n",
        "        'confusion_matrix': confusion_matrix(y_val, y_pred),\n",
        "        'classification_report': classification_report(y_val, y_pred, zero_division=0),\n",
        "    }\n",
        "joblib.dump(val_results, os.path.join(MODEL_DIR, 'validation_results.joblib'))\n",
        "print('Validation results saved to model/validation_results.joblib for Streamlit app.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_processed = preprocess_test(test_df)\n",
        "test_processed = test_processed[feature_cols].fillna(test_processed[feature_cols].median())\n",
        "X_test_scaled = scaler.transform(test_processed)\n",
        "# Example: predictions from Random Forest (no scaling)\n",
        "test_pred_rf = rf.predict(test_processed)\n",
        "test_out = test_df.copy()\n",
        "test_out['count_class_pred'] = test_pred_rf\n",
        "test_out.to_csv('bike_test_predictions.csv', index=False)\n",
        "print('Test predictions saved to bike_test_predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}